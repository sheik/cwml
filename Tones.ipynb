{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CW Sample Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from itertools import permutations\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MORSE_CODE_DICT = { \n",
    "    'A':'.-', \n",
    "    'B':'-...', \n",
    "    'C':'-.-.', \n",
    "    'D':'-..', \n",
    "    'E':'.', \n",
    "    'F':'..-.', \n",
    "    'G':'--.', \n",
    "    'H':'....', \n",
    "    'I':'..', \n",
    "    'J':'.---', \n",
    "    'K':'-.-',\n",
    "    'L':'.-..', \n",
    "    'M':'--', \n",
    "    'N':'-.', \n",
    "    'O':'---', \n",
    "    'P':'.--.', \n",
    "    'Q':'--.-',\n",
    "    'R':'.-.', \n",
    "    'S':'...', \n",
    "    'T':'-',\n",
    "    'U':'..-', \n",
    "    'V':'...-', \n",
    "    'W':'.--',\n",
    "    'X':'-..-', \n",
    "    'Y':'-.--', \n",
    "    'Z':'--..',\n",
    "    '1':'.----', \n",
    "    '2':'..---', \n",
    "    '3':'...--',\n",
    "    '4':'....-', \n",
    "    '5':'.....', \n",
    "    '6':'-....',\n",
    "    '7':'--...', \n",
    "    '8':'---..', \n",
    "    '9':'----.',\n",
    "    '0':'-----', \n",
    "    ',':'--..--', \n",
    "    '.':'.-.-.-',\n",
    "    '?':'..--..', \n",
    "    '/':'-..-.', \n",
    "    '-':'-....-',\n",
    "    '(':'-.--.', \n",
    "    ')':'-.--.-', \n",
    "    ' ': ' '\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_Dict_Stats = {}\n",
    "for k,v in MORSE_CODE_DICT.items():\n",
    "    if len(v) not in MC_Dict_Stats:\n",
    "        MC_Dict_Stats[len(v)]=1\n",
    "    else:\n",
    "        count = MC_Dict_Stats[len(v)]\n",
    "        MC_Dict_Stats[len(v)] = count+1\n",
    "        \n",
    "for k in sorted(MC_Dict_Stats):\n",
    "    v = MC_Dict_Stats[k]\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have seen Dit and Dah represented as . and -\n",
    "# What if we expand our vocabulary:\n",
    "# Dit: `\n",
    "# Dah: ~\n",
    "# letterStop: \".\"\n",
    "# WordStop: \" \"\n",
    "MORSE_CODE_DICT2={}\n",
    "STOPS = {\"Letter\": \"|\", \"Word\": \"_\"}\n",
    "\n",
    "for k, v in MORSE_CODE_DICT.items():\n",
    "    newV = v.replace('.', \"`\")\n",
    "    newV = newV.replace(\"-\",\"~\") \n",
    "    newV += STOPS[\"Letter\"]\n",
    "    MORSE_CODE_DICT2[k] = newV\n",
    "    \n",
    "print(MORSE_CODE_DICT2)              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the corpus\n",
    "with open(\"model_tf2/corpus.txt\") as fh:\n",
    "    dataString = fh.read()\n",
    "    \n",
    "print(dataString[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_Stats = {}\n",
    "for word in dataString.split():\n",
    "    if len(word) not in Word_Stats:\n",
    "        Word_Stats[len(word)]={word:1}\n",
    "    else:\n",
    "        count_list = Word_Stats[len(word)]\n",
    "        if word not in count_list:\n",
    "            count_list[word]=1\n",
    "        else:\n",
    "            qty = count_list[word] +1\n",
    "            count_list[word] = qty\n",
    "        Word_Stats[len(word)] = count_list\n",
    "    \n",
    "print(\"Word Length: \", \"Distinct Word Count: \", \"Occurences In Corpus:\")\n",
    "total_words = 0\n",
    "words_in_corpus=0\n",
    "for k in sorted(Word_Stats):\n",
    "    v = Word_Stats[k]\n",
    "    x=0\n",
    "    for w,c in v.items():\n",
    "        x+=c\n",
    "    words_in_corpus += x\n",
    "    total_words += len(v)\n",
    "    \n",
    "    print(\"{:11}\".format(k),  \"{:21}\".format(len(v)), \"{:22}\".format( x))\n",
    "    \n",
    "print(\"Total Distinct Words\", total_words)\n",
    "print(\"Total Words In Corpus\", words_in_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a new corpus\n",
    "dataString=\"\"\n",
    "\n",
    "corpa = [\"newhope.txt\", \"savingpvt.txt\", \"officespc.txt\", \"corpus.txt\", \"ai.txt\", \"frequency.txt\"]\n",
    "for t in corpa:\n",
    "    with open(\"model_tf2/{}\".format(t)) as fh:\n",
    "        dataString += fh.read()\n",
    "    \n",
    "print(dataString[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_Stats = {}\n",
    "for word in dataString.split():\n",
    "    if len(word) not in Word_Stats:\n",
    "        Word_Stats[len(word)]={word.upper():1}\n",
    "    else:\n",
    "        count_list = Word_Stats[len(word)]\n",
    "        if word not in count_list:\n",
    "            count_list[word.upper()]=1\n",
    "        else:\n",
    "            qty = count_list[word] +1\n",
    "            count_list[word.upper()] = qty\n",
    "        Word_Stats[len(word)] = count_list\n",
    "    \n",
    "print(\"Word Length: \", \"Distinct Word Count: \", \"Occurences In Corpus:\")\n",
    "total_words = 0\n",
    "words_in_corpus=0\n",
    "for k in sorted(Word_Stats):\n",
    "    v = Word_Stats[k]\n",
    "    x=0\n",
    "    for w,c in v.items():\n",
    "        x+=c\n",
    "    words_in_corpus += x\n",
    "    total_words += len(v)\n",
    "    \n",
    "    print(\"{:11}\".format(k),  \"{:21}\".format(len(v)), \"{:22}\".format( x))\n",
    "    \n",
    "print(\"Total Distinct Words\", total_words)\n",
    "print(\"Total Words In Corpus\", words_in_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Word_Stats[62].keys())\n",
    "print(Word_Stats[40].keys())\n",
    "print(Word_Stats[30].keys())\n",
    "print(Word_Stats[26].keys())\n",
    "print(Word_Stats[24].keys())\n",
    "print(Word_Stats[23].keys())\n",
    "print(Word_Stats[22].keys())\n",
    "print(Word_Stats[21].keys())\n",
    "print(Word_Stats[20].keys())\n",
    "print(Word_Stats[19].keys())\n",
    "print(Word_Stats[18].keys())\n",
    "print(Word_Stats[17].keys())\n",
    "print(Word_Stats[16].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a more organic distribution.  Select this as the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary of distinct words, spelled in the symbols from the MORSE_CODE_DICT2 dictionary\n",
    "Vocabulary = {}\n",
    "for k,v in Word_Stats.items():\n",
    "    for w in v.keys():\n",
    "        w_coded = w\n",
    "        for letter, code in MORSE_CODE_DICT2.items():\n",
    "            w_coded = w_coded.replace(letter,code)\n",
    "        #print(w,\"  \", w_coded, \"  \",w_coded[:-1]+STOPS[\"Word\"])\n",
    "        Vocabulary[w] = w_coded[:-1]+STOPS[\"Word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 44100\n",
    "freq = 600 #Hz\n",
    "wpm = 10.0\n",
    "\n",
    "# how many seconds to jitter the samples\n",
    "# this should allow for a better model by\n",
    "# giving more than one \"sample\" for each character\n",
    "JITTER_RANGE = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for generating tones and silence\n",
    "\n",
    "The following functions will generate a tone or silence based on \"time units\"\n",
    "\n",
    "These time units are all relative to eachother, and will ultimately change in length depending on the \"wpm\" variable\n",
    "\n",
    "Silence is simply a list of zeroes.\n",
    "\n",
    "Tones are a sin wave at freq Hz encoded into a list and normalized between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_silence(time_units):\n",
    "    return np.zeros(int(time_units * sample_rate / wpm))\n",
    "\n",
    "def generate_tone(time_units):\n",
    "    jitter = random.uniform(time_units*1.0-JITTER_RANGE,time_units*1.0+JITTER_RANGE)\n",
    "    t = np.linspace(0.0, jitter / wpm, int(sample_rate*jitter/wpm))\n",
    "    dit = np.sin(2.0 * np.pi * freq * t)\n",
    "    return dit / max(abs(dit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for generating dits, dahs, and various forms of silence\n",
    "\n",
    " * The length of a dot is 1 time unit.\n",
    " * A dash is 3 time units.\n",
    " * The space between symbols (dots and dashes) of the same letter is 1 time unit.\n",
    " * The space between letters is 3 time units.\n",
    " * The space between words is 7 time units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_sep = lambda: generate_silence(7)\n",
    "generate_letter_sep = lambda: generate_silence(3)\n",
    "generate_symbol_sep = lambda: generate_silence(1)\n",
    "generate_dah = lambda: generate_tone(3) \n",
    "generate_dit = lambda: generate_tone(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**encode(s)** will encode a string of text into morse code audio.\n",
    "\n",
    "The result is a list and is normalized between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s):\n",
    "    s = s.upper()\n",
    "    result = generate_silence(random.uniform(5,15))\n",
    "    for char in s:\n",
    "        try:\n",
    "            symbols = \"'\".join([i for i in MORSE_CODE_DICT[char]])\n",
    "            for symbol in symbols:\n",
    "                if symbol == '-':\n",
    "                    result = np.concatenate((result, generate_dah()))\n",
    "                elif symbol == '.':\n",
    "                    result = np.concatenate((result, generate_dit()))\n",
    "                elif symbol == \"'\":\n",
    "                    result = np.concatenate((result, generate_symbol_sep()))\n",
    "                elif symbol == ' ':\n",
    "                    result = np.concatenate((result, generate_word_sep()))\n",
    "            result = np.concatenate((result, generate_letter_sep()))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SNR(cw, dB)** will add white noise at the given dB level (positive and negative numbers work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNR(cw, dB):\n",
    "    SNR_linear = 10.0**(dB/10.0)\n",
    "    power = cw.var()\n",
    "    noise_power = power/SNR_linear\n",
    "    noise = np.sqrt(noise_power)*np.random.normal(0,1,len(cw))\n",
    "    return noise + cw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create WAV file\n",
    "Here is where the actual wav gets created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sorted_Vocab = sorted(Vocabulary.keys())\n",
    "wc = len(Sorted_Vocab)-1\n",
    "\n",
    "def RandomPhrase(min, max):\n",
    "        Random_Words = [Sorted_Vocab[random.randint(0,wc)] for i in range(0, random.randint(min,max))]\n",
    "        # print(Random_Words)\n",
    "        Test_Phrase = \" \".join(Random_Words)\n",
    "        return Test_Phrase\n",
    "    \n",
    "    \n",
    "for _ in range(0, 9):\n",
    "    print(RandomPhrase(5,15))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase = RandomPhrase(5,15)\n",
    "my_cq = SNR(encode(test_phrase), -6)\n",
    "write_wav(\"test.wav\", sample_rate, my_cq.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, sr = librosa.load('test.wav')\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(14, 5))\n",
    "_ = librosa.display.waveplot(x, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(x)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "_ = librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio('test.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Test Phrase Is:\\n{}\".format(test_phrase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Creating TensorFlow Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from matplotlib.mlab import specgram\n",
    "nfft = 256\n",
    "overlap = nfft - 56  # overlap value for spectrogram\n",
    "\n",
    "def get_specgram(signal, rate):\n",
    "    arr2D, freqs, bins = specgram(\n",
    "        signal,\n",
    "        window=np.blackman(nfft),\n",
    "        Fs=rate,\n",
    "        NFFT=nfft,\n",
    "        noverlap=overlap,\n",
    "        pad_to=32 * nfft,\n",
    "    )\n",
    "    return arr2D, freqs, bins\n",
    "\n",
    "def plot_image(arr2D, bins, freqs):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    extent = (bins[0], bins[-1], freqs[-1], freqs[0])\n",
    "    im = ax.imshow(\n",
    "        arr2D,\n",
    "        aspect=\"auto\",\n",
    "        extent=extent,\n",
    "        interpolation=\"none\",\n",
    "        cmap=\"Greys\",\n",
    "        norm=None,\n",
    "    )\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "def normalize_image(img):\n",
    "    # normalize\n",
    "    (m, s) = cv2.meanStdDev(img)\n",
    "    m = m[0][0]\n",
    "    s = s[0][0]\n",
    "    img = img - m\n",
    "    img = img / s if s>0 else img\n",
    "    return img\n",
    "\n",
    "\n",
    "def create_image(filename):\n",
    "    imgSize=(800, 32)\n",
    "    dataAugmentation=False\n",
    "\n",
    "    imgname = filename+\".png\"   \n",
    "\n",
    "    # Load  image in grayscale if exists\n",
    "    img = cv2.imread(imgname, 0) \n",
    "\n",
    "    # TODO: re-enable this IF statement\n",
    "    #if img is None:\n",
    "    rate, data = wavfile.read(filename)\n",
    "    arr2D, freqs, bins = get_specgram(data, rate)\n",
    "\n",
    "    # Get the image data array shape (Freq bins, Time Steps)\n",
    "    shape = arr2D.shape\n",
    "\n",
    "    # Find the CW spectrum peak - look across all time steps\n",
    "    f = int(np.argmax(arr2D[:]) / shape[1])\n",
    "\n",
    "    time_steps = (4.0/(len(data)/rate))*shape[1]\n",
    "\n",
    "    # Create a 32x128 array centered to spectrum peak\n",
    "    img = cv2.resize(arr2D[f - 16 : f + 16][:], imgSize)\n",
    "\n",
    "    img = normalize_image(img)\n",
    "\n",
    "    cv2.imwrite(imgname, img*256.)\n",
    "\n",
    "    img = normalize_image(img)  \n",
    "    # transpose for TF\n",
    "    img = cv2.transpose(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Image for Tensorlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image('test.wav')\n",
    "from IPython.display import Image\n",
    "Image(filename='test.wav.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus(ngram):\n",
    "    corpus = []\n",
    "    for i in permutations(MORSE_CODE_DICT.keys(), ngram):\n",
    "        corpus.append(\"\".join(i))\n",
    "    return corpus       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
