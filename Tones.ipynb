{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CW Sample Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from itertools import permutations\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MORSE_CODE_DICT = { 'A':'.-', 'B':'-...', \n",
    "                    'C':'-.-.', 'D':'-..', 'E':'.', \n",
    "                    'F':'..-.', 'G':'--.', 'H':'....', \n",
    "                    'I':'..', 'J':'.---', 'K':'-.-', \n",
    "                    'L':'.-..', 'M':'--', 'N':'-.', \n",
    "                    'O':'---', 'P':'.--.', 'Q':'--.-', \n",
    "                    'R':'.-.', 'S':'...', 'T':'-', \n",
    "                    'U':'..-', 'V':'...-', 'W':'.--', \n",
    "                    'X':'-..-', 'Y':'-.--', 'Z':'--..', \n",
    "                    '1':'.----', '2':'..---', '3':'...--', \n",
    "                    '4':'....-', '5':'.....', '6':'-....', \n",
    "                    '7':'--...', '8':'---..', '9':'----.', \n",
    "                    '0':'-----', ',':'--..--', '.':'.-.-.-', \n",
    "                    '?':'..--..', '/':'-..-.', '-':'-....-', \n",
    "                    '(':'-.--.', ')':'-.--.-', ' ': ' '} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 44100\n",
    "freq = 600 #Hz\n",
    "wpm = 5.0\n",
    "\n",
    "# how many seconds to jitter the samples\n",
    "# this should allow for a better model by\n",
    "# giving more than one \"sample\" for each character\n",
    "JITTER_RANGE = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for generating tones and silence\n",
    "\n",
    "The following functions will generate a tone or silence based on \"time units\"\n",
    "\n",
    "These time units are all relative to eachother, and will ultimately change in length depending on the \"wpm\" variable\n",
    "\n",
    "Silence is simply a list of zeroes.\n",
    "\n",
    "Tones are a sin wave at freq Hz encoded into a list and normalized between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_silence(time_units):\n",
    "    return np.zeros(int(time_units * sample_rate / wpm))\n",
    "\n",
    "def generate_tone(time_units):\n",
    "    jitter = random.uniform(time_units*1.0-JITTER_RANGE,time_units*1.0+JITTER_RANGE)\n",
    "    t = np.linspace(0.0, jitter / wpm, int(sample_rate*jitter/wpm))\n",
    "    dit = np.sin(2.0 * np.pi * freq * t)\n",
    "    return dit / max(abs(dit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for generating dits, dahs, and various forms of silence\n",
    "\n",
    " * The length of a dot is 1 time unit.\n",
    " * A dash is 3 time units.\n",
    " * The space between symbols (dots and dashes) of the same letter is 1 time unit.\n",
    " * The space between letters is 3 time units.\n",
    " * The space between words is 7 time units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_sep = lambda: generate_silence(7)\n",
    "generate_letter_sep = lambda: generate_silence(3)\n",
    "generate_symbol_sep = lambda: generate_silence(1)\n",
    "generate_dah = lambda: generate_tone(3) \n",
    "generate_dit = lambda: generate_tone(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**encode(s)** will encode a string of text into morse code audio.\n",
    "\n",
    "The result is a list and is normalized between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s):\n",
    "    s = s.upper()\n",
    "    result = generate_silence(random.uniform(5,15))\n",
    "    for char in s:\n",
    "        symbols = \"'\".join([i for i in MORSE_CODE_DICT[char]])\n",
    "        for symbol in symbols:\n",
    "            if symbol == '-':\n",
    "                result = np.concatenate((result, generate_dah()))\n",
    "            elif symbol == '.':\n",
    "                result = np.concatenate((result, generate_dit()))\n",
    "            elif symbol == \"'\":\n",
    "                result = np.concatenate((result, generate_symbol_sep()))\n",
    "            elif symbol == ' ':\n",
    "                result = np.concatenate((result, generate_word_sep()))\n",
    "        result = np.concatenate((result, generate_letter_sep()))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SNR(cw, dB)** will add white noise at the given dB level (positive and negative numbers work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNR(cw, dB):\n",
    "    SNR_linear = 10.0**(dB/10.0)\n",
    "    power = cw.var()\n",
    "    noise_power = power/SNR_linear\n",
    "    noise = np.sqrt(noise_power)*np.random.normal(0,1,len(cw))\n",
    "    return noise + cw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create WAV file\n",
    "Here is where the actual wav gets created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cq = SNR(encode(\"CQ CQ CQ DE KJ7PKQ\"), -6)\n",
    "write_wav(\"test.wav\", sample_rate, my_cq.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, sr = librosa.load('test.wav')\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(14, 5))\n",
    "_ = librosa.display.waveplot(x, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(x)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "_ = librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio('test.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Creating TensorFlow Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from matplotlib.mlab import specgram\n",
    "nfft = 256\n",
    "overlap = nfft - 56  # overlap value for spectrogram\n",
    "\n",
    "def get_specgram(signal, rate):\n",
    "    arr2D, freqs, bins = specgram(\n",
    "        signal,\n",
    "        window=np.blackman(nfft),\n",
    "        Fs=rate,\n",
    "        NFFT=nfft,\n",
    "        noverlap=overlap,\n",
    "        pad_to=32 * nfft,\n",
    "    )\n",
    "    return arr2D, freqs, bins\n",
    "\n",
    "def plot_image(arr2D, bins, freqs):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    extent = (bins[0], bins[-1], freqs[-1], freqs[0])\n",
    "    im = ax.imshow(\n",
    "        arr2D,\n",
    "        aspect=\"auto\",\n",
    "        extent=extent,\n",
    "        interpolation=\"none\",\n",
    "        cmap=\"Greys\",\n",
    "        norm=None,\n",
    "    )\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "def normalize_image(img):\n",
    "    # normalize\n",
    "    (m, s) = cv2.meanStdDev(img)\n",
    "    m = m[0][0]\n",
    "    s = s[0][0]\n",
    "    img = img - m\n",
    "    img = img / s if s>0 else img\n",
    "    return img\n",
    "\n",
    "\n",
    "def create_image(filename):\n",
    "    imgSize=(256, 32)\n",
    "    dataAugmentation=False\n",
    "\n",
    "    imgname = filename+\".png\"   \n",
    "\n",
    "    # Load  image in grayscale if exists\n",
    "    img = cv2.imread(imgname, 0) \n",
    "\n",
    "    # TODO: re-enable this IF statement\n",
    "    #if img is None:\n",
    "    rate, data = wavfile.read(filename)\n",
    "    arr2D, freqs, bins = get_specgram(data, rate)\n",
    "\n",
    "    # Get the image data array shape (Freq bins, Time Steps)\n",
    "    shape = arr2D.shape\n",
    "\n",
    "    # Find the CW spectrum peak - look across all time steps\n",
    "    f = int(np.argmax(arr2D[:]) / shape[1])\n",
    "\n",
    "    time_steps = (4.0/(len(data)/rate))*shape[1]\n",
    "\n",
    "    # Create a 32x128 array centered to spectrum peak\n",
    "    img = cv2.resize(arr2D[f - 16 : f + 16][:], imgSize)\n",
    "\n",
    "    img = normalize_image(img)\n",
    "\n",
    "    cv2.imwrite(imgname, img*256.)\n",
    "\n",
    "    img = normalize_image(img)  \n",
    "    # transpose for TF\n",
    "    img = cv2.transpose(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Image for Tensorlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image('test.wav')\n",
    "from IPython.display import Image\n",
    "Image(filename='test.wav.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus(ngram):\n",
    "    corpus = []\n",
    "    for i in permutations(MORSE_CODE_DICT.keys(), ngram):\n",
    "        corpus.append(\"\".join(i))\n",
    "    return corpus       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
